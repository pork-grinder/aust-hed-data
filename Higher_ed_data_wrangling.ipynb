{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadStatic():\n",
    "    '''a function to load static higher education provider data'''\n",
    "    \n",
    "    df = pd.read_csv(\"Provider.csv\").fillna(\n",
    "        value={'affiliation': 'NUHEP', 'affil_status': 'current'})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadEftsl():\n",
    "    '''a function to load equivalent full-time student load (eftsl)'''\n",
    "    \n",
    "    df = pd.read_csv('19_381_Onshore_EFTSL.csv')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def loadPerformance():\n",
    "    \n",
    "    '''a function to load, clean and join student success rate and attrition rate data'''\n",
    "    \n",
    "    #load success rate data\n",
    "    success_all = pd.read_csv(\"19_381_Onshore_success_rate_overall.csv\").rename(\n",
    "        columns = {\"success_rate\": \"success_all\"}).drop(['provider_name'], axis=1)\n",
    "    \n",
    "    success_dom = pd.read_csv(\"19_381_Onshore_success_domestic.csv\").rename(\n",
    "        columns = {\"success_rate\": \"success_dom\"})[['code_year', 'success_dom']]\n",
    "    \n",
    "    success_int = pd.read_csv(\"19_381_Onshore_success_international.csv\").rename(\n",
    "        columns = {\"success_rate\": \"success_int\"})[['code_year', 'success_int']]\n",
    "    \n",
    "    # load attrition rate data\n",
    "    attrition_all = pd.read_csv(\"19_381_Onshore_attrition_rate_overall.csv\").rename(\n",
    "        columns = {'attrition_rate': 'attrition_all'})[['code_year', 'attrition_all']]\n",
    "    \n",
    "    attrition_dom = pd.read_csv(\"19_381_Onshore_attrition_domestic.csv\").rename(\n",
    "        columns = {'attrition_rate': 'attrition_dom'})[['code_year', 'attrition_dom']]\n",
    "    \n",
    "    attrition_int = pd.read_csv(\"19_381_Onshore_attrition_international.csv\").rename(\n",
    "        columns = {'attrition_rate': 'attrition_int'})[['code_year', 'attrition_int']]\n",
    "    \n",
    "    # merge data frames\n",
    "    df = success_all.merge(success_dom, on='code_year', how = 'outer').merge(\n",
    "        success_int, on='code_year', how = 'outer').merge(\n",
    "        attrition_all, on='code_year', how = 'outer').merge(\n",
    "        attrition_dom, on='code_year', how = 'outer').merge(\n",
    "        attrition_int, on='code_year', how = 'outer')\n",
    "    \n",
    "    return df[df['ref_year'] > 2012]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadStaff(eftsl):\n",
    "\n",
    "    '''a function to load staff data and create important staff-related features'''\n",
    "    \n",
    "    # load .csv\n",
    "    staff = pd.read_csv('19_381_Academic_staff.csv').rename(\n",
    "        columns = {'tab1_academic_FTE': 'all_fte', \n",
    "                   'tab2_academic_FTE': 'salaried_fte', \n",
    "                   'tab3_senior_FTE': 'senior_fte', \n",
    "                   'tab3_senior_headcount_mod': 'senior_headcount'})\n",
    "    \n",
    "    # calculate pure staffing features\n",
    "    staff['sessional_fte'] = staff['all_fte'] - staff['salaried_fte']\n",
    "    staff['sessional_prop'] = staff['sessional_fte'] / staff['all_fte']\n",
    "    staff['senior_prop'] = staff['senior_fte'] / staff['all_fte']\n",
    "    \n",
    "    # join with eftsl data to enable calculation of student:staff ratio\n",
    "    eftsl_total = eftsl[['code_year', 'EFTSL']].groupby(['code_year']).sum().reset_index()\n",
    "    staff = staff.merge(eftsl_total, on='code_year').rename(columns={'EFTSL': 'eftsl'})\n",
    "    \n",
    "    # calculate student:staff ratios\n",
    "    staff['ssr_all'] = staff['eftsl'] / staff['all_fte']\n",
    "    staff['ssr_salaried'] = staff['eftsl'] / staff['salaried_fte']\n",
    "    \n",
    "    # select staffing features\n",
    "    df = staff[['code_year', \n",
    "                'all_fte', \n",
    "                'salaried_fte', \n",
    "                'senior_fte', \n",
    "                'senior_headcount', \n",
    "                'sessional_fte', \n",
    "                'sessional_prop', \n",
    "                'senior_prop', \n",
    "                'ssr_all']]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildPostgrad(eftsl):\n",
    "    \n",
    "    ''' a function to extract postgraduate student proportions from eftsl data'''\n",
    "    \n",
    "    # aggregate eftsl at course level by provider by year\n",
    "    df = eftsl.drop(['provider_code', 'ref_year'], axis=1).groupby(['Course_level','code_year']).sum().reset_index()\n",
    "    \n",
    "    # pivot in order to make columnwise calculation\n",
    "    df = df.pivot(index='code_year', columns='Course_level', values='EFTSL').fillna(value=0)\n",
    "    \n",
    "    # flatten index after pivoting\n",
    "    df.columns = [''.join(col).strip() for col in df.columns.values]\n",
    "    df.reset_index(inplace = True)\n",
    "    \n",
    "    # calculate postgraduate eftsl proportion and drop unnecessary columns\n",
    "    df['postgrad_prop'] = df['Postgrad by course'] / (df['Postgrad by course'] + df['Undergrad'])\n",
    "    df = df.drop(['Postgrad by course', 'Undergrad'], axis=1).fillna(value=0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildInternational(eftsl):\n",
    "    \n",
    "    ''' a function to extract international student proportions from eftsl data'''\n",
    "    \n",
    "    # aggregate eftsl at citizenship type (domestic or international) by provider by year\n",
    "    df = eftsl.drop(['provider_code', 'ref_year'], axis=1).groupby(['citizenship','code_year']).sum().reset_index()\n",
    "    \n",
    "    # pivot in order to make columnwise calculation\n",
    "    df = df.pivot(index='code_year', columns='citizenship', values='EFTSL').fillna(value=0)\n",
    "    \n",
    "    # flatten index after pivoting\n",
    "    df.columns = [''.join(col).strip() for col in df.columns.values]\n",
    "    df.reset_index(inplace = True)\n",
    "    \n",
    "    # calculate international eftsl proportion and drop unnecessary columns\n",
    "    df['int_prop'] = df['International'] / (df['International'] + df['Domestic'])\n",
    "    df = df.drop(['International', 'Domestic'], axis=1).fillna(value=0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildBfoe(eftsl):\n",
    "    \n",
    "    '''a function to generate eftsl and bfoe-related features'''\n",
    "\n",
    "    # aggregate eftsl at BFOE type by provider by year\n",
    "    df = eftsl.drop(['provider_code', 'ref_year'], axis=1).groupby(['primary_BFOE','code_year']).sum().reset_index()\n",
    "\n",
    "    # pivot wider and replace NAs with zeros to ensure each provider in each year has a value for each BFOE\n",
    "    df = df.pivot(index='code_year', columns='primary_BFOE', values='EFTSL').fillna(value=0)\n",
    "\n",
    "    # rename BFOE categories to be shorter\n",
    "    df = df.rename(columns = {'01 Natural and Physical Sciences': 'nat_phys_sci',\n",
    "                             '02 Information Technology': 'info_tech',\n",
    "                             '03 Engineering and Related Technologies': 'engineering',\n",
    "                             '04 Architecture and Building': 'arch_build',\n",
    "                             '05 Agriculture, Environmental and Related Studies': 'agri_env',\n",
    "                             '06 Health': 'health',\n",
    "                             '07 Education': 'education',\n",
    "                             '08 Management and Commerce': 'mge_com',\n",
    "                             '09 Society and Culture': 'soc_cult',\n",
    "                             '10 Creative Arts': 'creat_art',\n",
    "                             '11 Food, Hospitality and Personal Services': 'food_hosp',\n",
    "                             '12 Mixed Field Programmes': 'mixed',\n",
    "                             '13 Non-award courses': 'non_award'})\n",
    "\n",
    "    vars = ['nat_phys_sci', \n",
    "            'info_tech', \n",
    "            'engineering', \n",
    "            'arch_build', \n",
    "            'agri_env', \n",
    "            'health', \n",
    "            'education', \n",
    "            'mge_com', \n",
    "            'soc_cult', \n",
    "            'creat_art', \n",
    "            'food_hosp',\n",
    "            'mixed',\n",
    "            'non_award']\n",
    "\n",
    "    # flatten index after pivoting\n",
    "    df.columns = [''.join(col).strip() for col in df.columns.values]\n",
    "    df.reset_index(inplace = True)\n",
    "\n",
    "    # return to long format to implement column-wise calculations\n",
    "    df = pd.melt(df, id_vars=['code_year'], value_vars=vars, var_name='bfoe', value_name='eftsl')\n",
    "\n",
    "    # find max bfoe eftsl for each provider\n",
    "    df['bfoe_max'] = df.groupby(['code_year'])['eftsl'].transform(max)\n",
    "    df['bfoe_max'].replace(0, np.nan, inplace=True)\n",
    "\n",
    "    # caclulate total eftsl for ech provider\n",
    "    df['eftsl_sum'] = df.groupby(['code_year'])['eftsl'].transform(sum)\n",
    "\n",
    "    # calculate eftsl proportion for each bfoe for each provider for each year\n",
    "    df['eftsl_prop'] = df['eftsl'] / df['eftsl_sum']\n",
    "    df['eftsl_prop'].replace(0, np.nan, inplace=True)\n",
    "\n",
    "    # calculate values to be summed for entropy calculation\n",
    "    df['pre_entropy'] = -1*df['eftsl_prop']*np.log2(df['eftsl_prop'])\n",
    "\n",
    "    #calculate entropy\n",
    "    df['bfoe_entropy'] = df.groupby(['code_year'])['pre_entropy'].transform(sum)\n",
    "\n",
    "    # calculate values to be summed for gini impurity calculation\n",
    "    df['pre_gini'] = df['eftsl_prop']*(1-df['eftsl_prop'])\n",
    "\n",
    "    # calculate gini impurity\n",
    "    df['bfoe_gini_impurity'] = df.groupby(['code_year'])['pre_gini'].transform(sum)\n",
    "\n",
    "    #filter to only the max bfoe for any given year\n",
    "    df = df[df['bfoe_max'] == df['eftsl']] \n",
    "    df = df[df['bfoe_max'] != 0]\n",
    "\n",
    "    # drop unnecessary columns and rename as required\n",
    "    df = df.drop(['eftsl', 'bfoe_max', 'pre_entropy', 'pre_gini'], axis=1).rename(\n",
    "        columns={'bfoe': 'primary_bfoe', 'eftsl_prop': 'primary_bfoe_prop'})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadAverages():\n",
    "    \n",
    "    '''a function to load subsector averages published by TEQSA'''\n",
    "    \n",
    "    TEQSA_avg = pd.read_csv('TEQSA_averages.csv')\n",
    "    \n",
    "    return TEQSA_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDecisions():\n",
    "    decisions = pd.read_csv(\"https://data.gov.au/data/dataset/0c4f6591-2aea-4797-a127-ae8f8a0be0e2/resource/a61abca4-a4b7-4f17-a975-0bba20c2c73f/download/outcomes_26102020.csv\")\n",
    "    decisions = decisions.drop('Date',axis=1)\n",
    "    providers = pd.read_csv('https://data.gov.au/data/dataset/0c4f6591-2aea-4797-a127-ae8f8a0be0e2/resource/07370e3f-780b-4a70-8c87-b6796d5ab237/download/providers_21102020.csv')\n",
    "    providers = providers[['ProviderID', 'ProviderName', 'Category']]\n",
    "\n",
    "    decisions['Description'] = decisions.Title.str.rsplit(n=3).str[0]\n",
    "    decisions['Year'] = decisions.Title.str.rsplit(n=1).str[-1]\n",
    "\n",
    "    decisions = decisions.drop('Title',axis=1)\n",
    "\n",
    "    decisions['dec_condition'] = decisions['Text'].str.contains('ondition')|decisions['Description'].str.contains('ondition')\n",
    "    decisions['dec_staff_ratio'] = decisions['Text'].str.contains('staff ratio|SSR')\n",
    "    decisions['dec_sessional'] = decisions['Text'].str.contains('essional|asual')\n",
    "    decisions['dec_attrition'] = decisions['Text'].str.contains('ttrition')\n",
    "    decisions['dec_progress'] = decisions['Text'].str.contains('uccess|rogress')\n",
    "    decisions['dec_rejected'] = decisions['Description'].str.contains('reject|Reject|not|Not|Cancel r|cancel r|Cancel a|cancel a')|decisions['CourseID'].str.contains('reject|Reject')\n",
    "    decisions['extension'] = decisions['Description'].str.contains('Exten|exten')\n",
    "    decisions['dec_negative'] = decisions['Text'].str.contains('ondition')|decisions['Description'].str.contains('ondition')|decisions['Description'].str.contains('reject|Reject|not|Not|Cancel r|cancel r|Cancel a|cancel a')|decisions['CourseID'].str.contains('reject|Reject')\n",
    "\n",
    "    decisions = decisions[decisions['extension'] == False]\n",
    "\n",
    "    decisions = decisions.drop('Text',axis=1)\n",
    "    decisions['ProviderID'] = decisions['ProviderID'].str.strip()\n",
    "\n",
    "    decisions = providers.merge(decisions, on = 'ProviderID', how = 'outer')\n",
    "\n",
    "    decisions = decisions[decisions['Type'] == 'Decision']\n",
    "    decisions = decisions.drop('Type',axis=1)\n",
    "    decisions['DecisionType'] = decisions['DecisionType'].str.strip()\n",
    "\n",
    "    decisions = decisions[decisions.DecisionType.isin(['Re-registration', 'Registration'])]\n",
    "\n",
    "    decisions = decisions[[ 'ProviderID',\n",
    "                            'Year', \n",
    "                            'dec_negative',\n",
    "                            'dec_rejected',\n",
    "                            'dec_condition',\n",
    "                            'dec_staff_ratio',\n",
    "                            'dec_sessional',\n",
    "                            'dec_attrition',\n",
    "                            'dec_progress']]\n",
    "    decisions.rename(columns={\"ProviderID\" : \"prv\", \"Year\" : \"ref_year\"}, inplace=True)\n",
    "\n",
    "    return decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joinData():\n",
    "    '''a function to join all higher ed data frames''' \n",
    "\n",
    "    # load datasets\n",
    "    eftsl = loadEftsl()\n",
    "    provider = loadStatic()\n",
    "    performance = loadPerformance()\n",
    "    staff = loadStaff(eftsl)\n",
    "    teqsa_avg = loadAverages()\n",
    "    decisions = loadDecisions()[['prv', 'ref_year', 'dec_negative']].dropna().drop_duplicates()\n",
    "    decisions.ref_year = decisions.ref_year.astype(int)\n",
    "    \n",
    "    # transform eftsl data\n",
    "    bfoe = buildBfoe(eftsl)\n",
    "    postgrad = buildPostgrad(eftsl)\n",
    "    international = buildInternational(eftsl)\n",
    "\n",
    "    # join datasets\n",
    "    df = provider.merge(performance, on='provider_code', how = 'outer').merge(\n",
    "        staff, on='code_year', how = 'outer').merge(\n",
    "        bfoe, on='code_year', how = 'outer').merge(\n",
    "        postgrad, on='code_year', how = 'outer').merge(\n",
    "        international, on='code_year', how = 'outer').merge(\n",
    "        teqsa_avg, on=['TEQSA_type', 'ref_year'], how = 'outer').merge(\n",
    "        decisions, on=['prv', 'ref_year'], how = 'left')\n",
    "    # remove providers without a name\n",
    "    df = df[df.provider_name.notnull()]\n",
    "\n",
    "    # remove ref_year before 2012\n",
    "    df = df[df['ref_year'] > 2011]\n",
    "\n",
    "    df.ref_year = df.ref_year.astype(int)\n",
    "\n",
    "    # remove providers that no longer existed in the last year of the data collection (2017)\n",
    "    still_exists = list(df[df['ref_year'] == 2017]['prv'])\n",
    "    df = df[df.prv.isin(still_exists)]\n",
    "\n",
    "    # replace unlikely values with null\n",
    "    df['ssr_all'] = np.where((df.ssr_all < 0.00001), np.NaN ,df.ssr_all)\n",
    "    df['sessional_prop'] = np.where((df.sessional_prop < 0.00001), np.NaN ,df.sessional_prop)\n",
    "    df['sessional_prop'] = np.where((df.sessional_prop > 0.99999), np.NaN ,df.sessional_prop)\n",
    "\n",
    "\n",
    "    # remove redundant provider code\n",
    "    df = df.drop(['provider_code'], axis=1)\n",
    "    \n",
    "    # select and order columns\n",
    "    \n",
    "\n",
    "    return df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute(df):\n",
    "    '''a function to impute missing values using MICE'''\n",
    "    \n",
    "    # select numeric features\n",
    "    df2 = df[['primary_bfoe_prop',\n",
    "                'bfoe_entropy',\n",
    "                'bfoe_gini_impurity',\n",
    "                'postgrad_prop',\n",
    "                'int_prop',\n",
    "                'sessional_prop_type_avg',\n",
    "                'sessional_prop',\n",
    "                'senior_prop',\n",
    "                'ssr_all_type_avg',\n",
    "                'ssr_salaried_type_avg',\n",
    "                'ssr_all',\n",
    "                'success_dom',\n",
    "                'success_int',\n",
    "                'success_all',\n",
    "                'attrition_dom',\n",
    "                'attrition_int',\n",
    "                'attrition_all']]\n",
    "\n",
    "    # specify minimum and maximum values for imputation\n",
    "    min = [0.01, 0, 0, 0, 0, 0.01, 0.01, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n",
    "    max = [1, 3.05, 1, 1, 1, 1, 1, 1, 100, 100, 100, 100, 100, 100, 100, 100, 100]\n",
    "    \n",
    "    # instantiate imputer\n",
    "    mice_imputer = IterativeImputer(max_iter=10000, random_state=1, min_value=min, max_value=max)\n",
    "    \n",
    "    # fit imputation and return as a dataframe\n",
    "    df_imp = pd.DataFrame(mice_imputer.fit_transform(df2).round(decimals=6))\n",
    "    \n",
    "    # rename imputed columns\n",
    "    df_imp.columns = ['primary_bfoe_prop',\n",
    "                'bfoe_entropy',\n",
    "                'bfoe_gini_impurity',\n",
    "                'postgrad_prop',\n",
    "                'int_prop',\n",
    "                'sessional_prop_type_avg',\n",
    "                'sessional_prop',\n",
    "                'senior_prop',\n",
    "                'ssr_all_type_avg',\n",
    "                'ssr_salaried_type_avg',\n",
    "                'ssr_all',\n",
    "                'success_dom',\n",
    "                'success_int',\n",
    "                'success_all',\n",
    "                'attrition_dom',\n",
    "                'attrition_int',\n",
    "                'attrition_all']\n",
    "    \n",
    "    # specify columns to be overwritten with imputed data, noting that cells without NAs will be untouched\n",
    "    columns_to_overwrite = ['primary_bfoe_prop',\n",
    "                'bfoe_entropy',\n",
    "                'bfoe_gini_impurity',\n",
    "                'postgrad_prop',\n",
    "                'int_prop',\n",
    "                'sessional_prop_type_avg',\n",
    "                'sessional_prop',\n",
    "                'senior_prop',\n",
    "                'ssr_all_type_avg',\n",
    "                'ssr_salaried_type_avg',\n",
    "                'ssr_all',\n",
    "                'success_dom',\n",
    "                'success_int',\n",
    "                'success_all',\n",
    "                'attrition_dom',\n",
    "                'attrition_int',\n",
    "                'attrition_all']\n",
    "    \n",
    "    # drop columns to be overwritten from original dataset and replace with imputed data\n",
    "    df3 = df.drop(columns_to_overwrite, axis=1)\n",
    "    df3[columns_to_overwrite] = df_imp[columns_to_overwrite]\n",
    "\n",
    "    return df3[df3['ssr_all'] >0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def staffAdjust(df_imp, sessional_multiplier = 1, ssr_multiplier = 1):\n",
    "    \n",
    "    df_imp = df_imp\n",
    "    \n",
    "    '''a function to adjust imputed staffing values based on sub-sector averages published by TEQSA'''\n",
    "\n",
    "    compare = df_imp[['ref_year','TEQSA_type',\n",
    "                    'sessional_prop_type_avg',\n",
    "                    'sessional_prop',\n",
    "                    'ssr_all_type_avg',\n",
    "                    'ssr_salaried_type_avg',\n",
    "                    'ssr_all']]\n",
    "\n",
    "    agg = compare.groupby(['ref_year','TEQSA_type']).mean().reset_index()\n",
    "    agg['sessional_diff'] = agg['sessional_prop_type_avg'] - agg['sessional_prop']\n",
    "    agg['ssr_all_diff'] = agg['ssr_all_type_avg'] - agg['ssr_all']\n",
    "    diff = agg.drop(['sessional_prop_type_avg', 'sessional_prop', 'ssr_all_type_avg', 'ssr_all', 'ssr_salaried_type_avg'], axis=1)\n",
    "\n",
    "    df_diff = df_imp.merge(diff, on=['ref_year', 'TEQSA_type'], how = 'left')\n",
    "\n",
    "    df_diff.loc[df_diff.TEQSA_type!='university', 'sessional_prop'] = sessional_multiplier * (df_diff.loc[df_diff.TEQSA_type!='university', 'sessional_prop'] + df_diff.loc[df_diff.TEQSA_type!='university', 'sessional_diff'])\n",
    "    df_diff.loc[df_diff.TEQSA_type!='university', 'ssr_all'] = ssr_multiplier * (df_diff.loc[df_diff.TEQSA_type!='university', 'ssr_all'] + df_diff.loc[df_diff.TEQSA_type!='university', 'ssr_all_diff'])\n",
    "\n",
    "    df_diff = df_diff.drop(['sessional_diff', 'ssr_all_diff', 'sessional_prop_type_avg', 'ssr_all_type_avg', 'ssr_salaried_type_avg'], axis=1)\n",
    "\n",
    "    df_diff['ssr_salaried'] = df_diff['ssr_all'] * (1 / (1 - df_diff['sessional_prop']))\n",
    "    \n",
    "    df = df_diff[['code_year',\n",
    "            'prv',\n",
    "            'provider_name',\n",
    "            'ref_year',\n",
    "            'type',\n",
    "            'TEQSA_type',\n",
    "            'ownership',\n",
    "            'profit',\n",
    "            'affiliation',\n",
    "            'affil_status',\n",
    "            'eftsl_sum',\n",
    "            'primary_bfoe',\n",
    "            'primary_bfoe_prop',\n",
    "            'bfoe_entropy',\n",
    "            'bfoe_gini_impurity',\n",
    "            'postgrad_prop',\n",
    "            'int_prop',\n",
    "            'sessional_prop',\n",
    "            'senior_prop',\n",
    "            'ssr_all',\n",
    "            'ssr_salaried',\n",
    "            'success_dom',\n",
    "            'success_int',\n",
    "            'success_all',\n",
    "            'attrition_dom',\n",
    "            'attrition_int',\n",
    "            'attrition_all',\n",
    "            'dec_negative']]\n",
    "\n",
    "    return df.round(decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    df_raw = joinData()\n",
    "    df_imp = impute(df_raw)\n",
    "    df = staffAdjust(df_imp)\n",
    "    #df.to_csv('higher_ed_data.csv', index = False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_year</th>\n",
       "      <th>prv</th>\n",
       "      <th>provider_name</th>\n",
       "      <th>ref_year</th>\n",
       "      <th>type</th>\n",
       "      <th>TEQSA_type</th>\n",
       "      <th>ownership</th>\n",
       "      <th>profit</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>affil_status</th>\n",
       "      <th>...</th>\n",
       "      <th>senior_prop</th>\n",
       "      <th>ssr_all</th>\n",
       "      <th>ssr_salaried</th>\n",
       "      <th>success_dom</th>\n",
       "      <th>success_int</th>\n",
       "      <th>success_all</th>\n",
       "      <th>attrition_dom</th>\n",
       "      <th>attrition_int</th>\n",
       "      <th>attrition_all</th>\n",
       "      <th>dec_negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3006-2013</td>\n",
       "      <td>PRV12008</td>\n",
       "      <td>Australian Catholic University Limited</td>\n",
       "      <td>2013</td>\n",
       "      <td>university</td>\n",
       "      <td>university</td>\n",
       "      <td>public</td>\n",
       "      <td>not_for_profit</td>\n",
       "      <td>non_aligned</td>\n",
       "      <td>current</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146</td>\n",
       "      <td>19.063</td>\n",
       "      <td>30.701</td>\n",
       "      <td>89.20</td>\n",
       "      <td>88.16</td>\n",
       "      <td>89.10</td>\n",
       "      <td>14.14</td>\n",
       "      <td>13.36</td>\n",
       "      <td>14.06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3033-2013</td>\n",
       "      <td>PRV12002</td>\n",
       "      <td>Australian National University</td>\n",
       "      <td>2013</td>\n",
       "      <td>university</td>\n",
       "      <td>university</td>\n",
       "      <td>public</td>\n",
       "      <td>not_for_profit</td>\n",
       "      <td>Go8</td>\n",
       "      <td>current</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318</td>\n",
       "      <td>7.107</td>\n",
       "      <td>7.640</td>\n",
       "      <td>92.86</td>\n",
       "      <td>93.90</td>\n",
       "      <td>93.16</td>\n",
       "      <td>10.17</td>\n",
       "      <td>3.51</td>\n",
       "      <td>8.72</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3003-2013</td>\n",
       "      <td>PRV12072</td>\n",
       "      <td>Bond University Limited</td>\n",
       "      <td>2013</td>\n",
       "      <td>university</td>\n",
       "      <td>university</td>\n",
       "      <td>private</td>\n",
       "      <td>not_for_profit</td>\n",
       "      <td>non_aligned</td>\n",
       "      <td>current</td>\n",
       "      <td>...</td>\n",
       "      <td>0.367</td>\n",
       "      <td>13.758</td>\n",
       "      <td>18.400</td>\n",
       "      <td>76.90</td>\n",
       "      <td>88.60</td>\n",
       "      <td>80.18</td>\n",
       "      <td>11.00</td>\n",
       "      <td>9.04</td>\n",
       "      <td>10.44</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2200-2013</td>\n",
       "      <td>PRV12073</td>\n",
       "      <td>Central Queensland University</td>\n",
       "      <td>2013</td>\n",
       "      <td>university</td>\n",
       "      <td>university</td>\n",
       "      <td>public</td>\n",
       "      <td>not_for_profit</td>\n",
       "      <td>RUN</td>\n",
       "      <td>current</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184</td>\n",
       "      <td>21.365</td>\n",
       "      <td>25.980</td>\n",
       "      <td>83.37</td>\n",
       "      <td>82.93</td>\n",
       "      <td>83.24</td>\n",
       "      <td>26.48</td>\n",
       "      <td>16.59</td>\n",
       "      <td>23.32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3001-2013</td>\n",
       "      <td>PRV12069</td>\n",
       "      <td>Charles Darwin University</td>\n",
       "      <td>2013</td>\n",
       "      <td>university</td>\n",
       "      <td>university</td>\n",
       "      <td>public</td>\n",
       "      <td>not_for_profit</td>\n",
       "      <td>IRU</td>\n",
       "      <td>current</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169</td>\n",
       "      <td>17.570</td>\n",
       "      <td>18.899</td>\n",
       "      <td>82.15</td>\n",
       "      <td>81.70</td>\n",
       "      <td>82.08</td>\n",
       "      <td>26.08</td>\n",
       "      <td>9.88</td>\n",
       "      <td>24.53</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   code_year       prv                           provider_name  ref_year  \\\n",
       "0  3006-2013  PRV12008  Australian Catholic University Limited      2013   \n",
       "1  3033-2013  PRV12002          Australian National University      2013   \n",
       "2  3003-2013  PRV12072                 Bond University Limited      2013   \n",
       "3  2200-2013  PRV12073           Central Queensland University      2013   \n",
       "4  3001-2013  PRV12069               Charles Darwin University      2013   \n",
       "\n",
       "         type  TEQSA_type ownership          profit  affiliation affil_status  \\\n",
       "0  university  university    public  not_for_profit  non_aligned      current   \n",
       "1  university  university    public  not_for_profit          Go8      current   \n",
       "2  university  university   private  not_for_profit  non_aligned      current   \n",
       "3  university  university    public  not_for_profit          RUN      current   \n",
       "4  university  university    public  not_for_profit          IRU      current   \n",
       "\n",
       "   ...  senior_prop ssr_all  ssr_salaried  success_dom  success_int  \\\n",
       "0  ...        0.146  19.063        30.701        89.20        88.16   \n",
       "1  ...        0.318   7.107         7.640        92.86        93.90   \n",
       "2  ...        0.367  13.758        18.400        76.90        88.60   \n",
       "3  ...        0.184  21.365        25.980        83.37        82.93   \n",
       "4  ...        0.169  17.570        18.899        82.15        81.70   \n",
       "\n",
       "   success_all  attrition_dom  attrition_int  attrition_all  dec_negative  \n",
       "0        89.10          14.14          13.36          14.06           NaN  \n",
       "1        93.16          10.17           3.51           8.72         False  \n",
       "2        80.18          11.00           9.04          10.44           NaN  \n",
       "3        83.24          26.48          16.59          23.32           NaN  \n",
       "4        82.08          26.08           9.88          24.53           NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = main()\n",
    "\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
