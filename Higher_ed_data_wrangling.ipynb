{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadStatic():\n",
    "    '''a function to load static higher education provider data'''\n",
    "    \n",
    "    df = pd.read_csv(\"Provider.csv\").fillna(\n",
    "        value={'affiliation': 'NUHEP', 'affil_status': 'current'})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadEftsl():\n",
    "    '''a function to load equivalent full-time student load (eftsl)'''\n",
    "    \n",
    "    df = pd.read_csv('19_381_Onshore_EFTSL.csv')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def loadPerformance():\n",
    "    \n",
    "    '''a function to load, clean and join student success rate and attrition rate data'''\n",
    "    \n",
    "    #load success rate data\n",
    "    success_all = pd.read_csv(\"19_381_Onshore_success_rate_overall.csv\").rename(\n",
    "        columns = {\"success_rate\": \"success_all\"}).drop(['provider_name'], axis=1)\n",
    "    \n",
    "    success_dom = pd.read_csv(\"19_381_Onshore_success_domestic.csv\").rename(\n",
    "        columns = {\"success_rate\": \"success_dom\"})[['code_year', 'success_dom']]\n",
    "    \n",
    "    success_int = pd.read_csv(\"19_381_Onshore_success_international.csv\").rename(\n",
    "        columns = {\"success_rate\": \"success_int\"})[['code_year', 'success_int']]\n",
    "    \n",
    "    # load attrition rate data\n",
    "    attrition_all = pd.read_csv(\"19_381_Onshore_attrition_rate_overall.csv\").rename(\n",
    "        columns = {'attrition_rate': 'attrition_all'})[['code_year', 'attrition_all']]\n",
    "    \n",
    "    attrition_dom = pd.read_csv(\"19_381_Onshore_attrition_domestic.csv\").rename(\n",
    "        columns = {'attrition_rate': 'attrition_dom'})[['code_year', 'attrition_dom']]\n",
    "    \n",
    "    attrition_int = pd.read_csv(\"19_381_Onshore_attrition_international.csv\").rename(\n",
    "        columns = {'attrition_rate': 'attrition_int'})[['code_year', 'attrition_int']]\n",
    "    \n",
    "    # merge data frames\n",
    "    df = success_all.merge(success_dom, on='code_year', how = 'outer').merge(\n",
    "        success_int, on='code_year', how = 'outer').merge(\n",
    "        attrition_all, on='code_year', how = 'outer').merge(\n",
    "        attrition_dom, on='code_year', how = 'outer').merge(\n",
    "        attrition_int, on='code_year', how = 'outer')\n",
    "    \n",
    "    return df[df['ref_year'] > 2012]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadStaff(eftsl):\n",
    "\n",
    "    '''a function to load staff data and create important staff-related features'''\n",
    "    \n",
    "    # load .csv\n",
    "    staff = pd.read_csv('19_381_Academic_staff.csv').rename(\n",
    "        columns = {'tab1_academic_FTE': 'all_fte', \n",
    "                   'tab2_academic_FTE': 'salaried_fte', \n",
    "                   'tab3_senior_FTE': 'senior_fte', \n",
    "                   'tab3_senior_headcount_mod': 'senior_headcount'})\n",
    "    \n",
    "    # calculate pure staffing features\n",
    "    staff['sessional_fte'] = staff['all_fte'] - staff['salaried_fte']\n",
    "    staff['sessional_prop'] = staff['sessional_fte'] / staff['all_fte']\n",
    "    staff['senior_prop'] = staff['senior_fte'] / staff['all_fte']\n",
    "    \n",
    "    # join with eftsl data to enable calculation of student:staff ratio\n",
    "    eftsl_total = eftsl[['code_year', 'EFTSL']].groupby(['code_year']).sum().reset_index()\n",
    "    staff = staff.merge(eftsl_total, on='code_year').rename(columns={'EFTSL': 'eftsl'})\n",
    "    \n",
    "    # calculate student:staff ratios\n",
    "    staff['ssr_all'] = staff['eftsl'] / staff['all_fte']\n",
    "    staff['ssr_salaried'] = staff['eftsl'] / staff['salaried_fte']\n",
    "    \n",
    "    # select staffing features\n",
    "    df = staff[['code_year', \n",
    "                'all_fte', \n",
    "                'salaried_fte', \n",
    "                'senior_fte', \n",
    "                'senior_headcount', \n",
    "                'sessional_fte', \n",
    "                'sessional_prop', \n",
    "                'senior_prop', \n",
    "                'ssr_all']]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildPostgrad(eftsl):\n",
    "    \n",
    "    ''' a function to extract postgraduate student proportions from eftsl data'''\n",
    "    \n",
    "    # aggregate eftsl at course level by provider by year\n",
    "    df = eftsl.drop(['provider_code', 'ref_year'], axis=1).groupby(['Course_level','code_year']).sum().reset_index()\n",
    "    \n",
    "    # pivot in order to make columnwise calculation\n",
    "    df = df.pivot(index='code_year', columns='Course_level', values='EFTSL').fillna(value=0)\n",
    "    \n",
    "    # flatten index after pivoting\n",
    "    df.columns = [''.join(col).strip() for col in df.columns.values]\n",
    "    df.reset_index(inplace = True)\n",
    "    \n",
    "    # calculate postgraduate eftsl proportion and drop unnecessary columns\n",
    "    df['postgrad_prop'] = df['Postgrad by course'] / (df['Postgrad by course'] + df['Undergrad'])\n",
    "    df = df.drop(['Postgrad by course', 'Undergrad'], axis=1).fillna(value=0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildInternational(eftsl):\n",
    "    \n",
    "    ''' a function to extract international student proportions from eftsl data'''\n",
    "    \n",
    "    # aggregate eftsl at citizenship type (domestic or international) by provider by year\n",
    "    df = eftsl.drop(['provider_code', 'ref_year'], axis=1).groupby(['citizenship','code_year']).sum().reset_index()\n",
    "    \n",
    "    # pivot in order to make columnwise calculation\n",
    "    df = df.pivot(index='code_year', columns='citizenship', values='EFTSL').fillna(value=0)\n",
    "    \n",
    "    # flatten index after pivoting\n",
    "    df.columns = [''.join(col).strip() for col in df.columns.values]\n",
    "    df.reset_index(inplace = True)\n",
    "    \n",
    "    # calculate international eftsl proportion and drop unnecessary columns\n",
    "    df['int_prop'] = df['International'] / (df['International'] + df['Domestic'])\n",
    "    df = df.drop(['International', 'Domestic'], axis=1).fillna(value=0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildBfoe(eftsl):\n",
    "    \n",
    "    '''a function to generate eftsl and bfoe-related features'''\n",
    "\n",
    "    # aggregate eftsl at BFOE type by provider by year\n",
    "    df = eftsl.drop(['provider_code', 'ref_year'], axis=1).groupby(['primary_BFOE','code_year']).sum().reset_index()\n",
    "\n",
    "    # pivot wider and replace NAs with zeros to ensure each provider in each year has a value for each BFOE\n",
    "    df = df.pivot(index='code_year', columns='primary_BFOE', values='EFTSL').fillna(value=0)\n",
    "\n",
    "    # rename BFOE categories to be shorter\n",
    "    df = df.rename(columns = {'01 Natural and Physical Sciences': 'nat_phys_sci',\n",
    "                             '02 Information Technology': 'info_tech',\n",
    "                             '03 Engineering and Related Technologies': 'engineering',\n",
    "                             '04 Architecture and Building': 'arch_build',\n",
    "                             '05 Agriculture, Environmental and Related Studies': 'agri_env',\n",
    "                             '06 Health': 'health',\n",
    "                             '07 Education': 'education',\n",
    "                             '08 Management and Commerce': 'mge_com',\n",
    "                             '09 Society and Culture': 'soc_cult',\n",
    "                             '10 Creative Arts': 'creat_art',\n",
    "                             '11 Food, Hospitality and Personal Services': 'food_hosp',\n",
    "                             '12 Mixed Field Programmes': 'mixed',\n",
    "                             '13 Non-award courses': 'non_award'})\n",
    "\n",
    "    vars = ['nat_phys_sci', \n",
    "            'info_tech', \n",
    "            'engineering', \n",
    "            'arch_build', \n",
    "            'agri_env', \n",
    "            'health', \n",
    "            'education', \n",
    "            'mge_com', \n",
    "            'soc_cult', \n",
    "            'creat_art', \n",
    "            'food_hosp',\n",
    "            'mixed',\n",
    "            'non_award']\n",
    "\n",
    "    # flatten index after pivoting\n",
    "    df.columns = [''.join(col).strip() for col in df.columns.values]\n",
    "    df.reset_index(inplace = True)\n",
    "\n",
    "    # return to long format to implement column-wise calculations\n",
    "    df = pd.melt(df, id_vars=['code_year'], value_vars=vars, var_name='bfoe', value_name='eftsl')\n",
    "\n",
    "    # find max bfoe eftsl for each provider\n",
    "    df['bfoe_max'] = df.groupby(['code_year'])['eftsl'].transform(max)\n",
    "    df['bfoe_max'].replace(0, np.nan, inplace=True)\n",
    "\n",
    "    # caclulate total eftsl for ech provider\n",
    "    df['eftsl_sum'] = df.groupby(['code_year'])['eftsl'].transform(sum)\n",
    "\n",
    "    # calculate eftsl proportion for each bfoe for each provider for each year\n",
    "    df['eftsl_prop'] = df['eftsl'] / df['eftsl_sum']\n",
    "    df['eftsl_prop'].replace(0, np.nan, inplace=True)\n",
    "\n",
    "    # calculate values to be summed for entropy calculation\n",
    "    df['pre_entropy'] = -1*df['eftsl_prop']*np.log2(df['eftsl_prop'])\n",
    "\n",
    "    #calculate entropy\n",
    "    df['bfoe_entropy'] = df.groupby(['code_year'])['pre_entropy'].transform(sum)\n",
    "\n",
    "    # calculate values to be summed for gini impurity calculation\n",
    "    df['pre_gini'] = df['eftsl_prop']*(1-df['eftsl_prop'])\n",
    "\n",
    "    # calculate gini impurity\n",
    "    df['bfoe_gini_impurity'] = df.groupby(['code_year'])['pre_gini'].transform(sum)\n",
    "\n",
    "    #filter to only the max bfoe for any given year\n",
    "    df = df[df['bfoe_max'] == df['eftsl']] \n",
    "    df = df[df['bfoe_max'] != 0]\n",
    "\n",
    "    # drop unnecessary columns and rename as required\n",
    "    df = df.drop(['eftsl', 'bfoe_max', 'pre_entropy', 'pre_gini'], axis=1).rename(\n",
    "        columns={'bfoe': 'primary_bfoe', 'eftsl_prop': 'primary_bfoe_prop'})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadAverages():\n",
    "    \n",
    "    '''a function to load subsector averages published by TEQSA'''\n",
    "    \n",
    "    TEQSA_avg = pd.read_csv('TEQSA_averages.csv')\n",
    "    \n",
    "    return TEQSA_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDecisions(max_year = 2017):\n",
    "    decisions = pd.read_csv(\"https://data.gov.au/data/dataset/0c4f6591-2aea-4797-a127-ae8f8a0be0e2/resource/a61abca4-a4b7-4f17-a975-0bba20c2c73f/download/outcomes_26102020.csv\")\n",
    "    decisions = decisions.drop('Date',axis=1)\n",
    "    \n",
    "    providers = pd.read_csv('https://data.gov.au/data/dataset/0c4f6591-2aea-4797-a127-ae8f8a0be0e2/resource/07370e3f-780b-4a70-8c87-b6796d5ab237/download/providers_21102020.csv')\n",
    "    providers = providers[['ProviderID', 'ProviderName', 'Category']]\n",
    "\n",
    "    decisions['Description'] = decisions.Title.str.rsplit(n=3).str[0]\n",
    "    decisions['Year'] = decisions.Title.str.rsplit(n=1).str[-1]\n",
    "\n",
    "    decisions = decisions.drop('Title',axis=1)\n",
    "\n",
    "    decisions['dec_condition'] = decisions['Text'].str.contains(\n",
    "        'ondition')|decisions['Description'].str.contains(\n",
    "        'ondition')\n",
    "    decisions['dec_staff_ratio'] = decisions['Text'].str.contains('staff ratio|SSR')\n",
    "    decisions['dec_sessional'] = decisions['Text'].str.contains('essional|asual')\n",
    "    decisions['dec_attrition'] = decisions['Text'].str.contains('ttrition')\n",
    "    decisions['dec_progress'] = decisions['Text'].str.contains('uccess|rogress')\n",
    "    decisions['dec_rejected'] = (decisions['Description'].str.contains('reject|Reject|not|Not|Cancel r|cancel r|Cancel a|cancel a')|\n",
    "                                 decisions['CourseID'].str.contains('reject|Reject'))\n",
    "    decisions['extension'] = decisions['Description'].str.contains('Exten|exten')\n",
    "    \n",
    "    decisions['dec_any_adverse'] = (decisions['dec_rejected']|\n",
    "                decisions['dec_condition']|\n",
    "                decisions['dec_staff_ratio']|\n",
    "                decisions['dec_sessional']|\n",
    "                decisions['dec_attrition']|\n",
    "                decisions['dec_progress'])\n",
    "\n",
    "    decisions['dec_formal_adverse'] = (decisions['dec_rejected']|\n",
    "                    decisions['dec_condition'])\n",
    "    \n",
    "    decisions = decisions[decisions['extension'] == False]\n",
    "\n",
    "    decisions = decisions.drop('Text',axis=1)\n",
    "    decisions['ProviderID'] = decisions['ProviderID'].str.strip()\n",
    "\n",
    "    decisions = providers.merge(decisions, on = 'ProviderID', how = 'outer')\n",
    "\n",
    "    decisions = decisions[decisions['Type'] == 'Decision']\n",
    "    decisions = decisions.drop('Type',axis=1)\n",
    "    decisions['DecisionType'] = decisions['DecisionType'].str.strip()\n",
    "\n",
    "    decisions = decisions[decisions.DecisionType.isin(['Registration',\n",
    "                                                       'Re-registration',\n",
    "                                                       'Re-accreditation', \n",
    "                                                       'Accreditation'])]\n",
    "\n",
    "    decisions = decisions[[ 'ProviderID',\n",
    "                            'Year', \n",
    "                            'DecisionType',\n",
    "                            'dec_any_adverse',\n",
    "                            'dec_formal_adverse',\n",
    "                            'dec_rejected',\n",
    "                            'dec_condition',\n",
    "                            'dec_staff_ratio',\n",
    "                            'dec_sessional',\n",
    "                            'dec_attrition',\n",
    "                            'dec_progress']]\n",
    "    decisions.rename(columns={\"ProviderID\" : \"prv\", \"Year\" : \"ref_year\"}, inplace=True)\n",
    "    \n",
    "    decisions.ref_year = pd.to_numeric(decisions.ref_year, errors='coerce').astype('Int64')\n",
    "\n",
    "    decisions[decisions['ref_year'] > max_year] = max_year\n",
    "\n",
    "    return decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joinData():\n",
    "    '''a function to join all higher ed data frames''' \n",
    "\n",
    "    # load datasets\n",
    "    eftsl = loadEftsl()\n",
    "    provider = loadStatic()\n",
    "    performance = loadPerformance()\n",
    "    staff = loadStaff(eftsl)\n",
    "    teqsa_avg = loadAverages()\n",
    "    \n",
    "    # transform eftsl data\n",
    "    bfoe = buildBfoe(eftsl)\n",
    "    postgrad = buildPostgrad(eftsl)\n",
    "    international = buildInternational(eftsl)\n",
    "\n",
    "    # join datasets\n",
    "    df = provider.merge(performance, on='provider_code', how = 'outer').merge(\n",
    "        staff, on='code_year', how = 'outer').merge(\n",
    "        bfoe, on='code_year', how = 'outer').merge(\n",
    "        postgrad, on='code_year', how = 'outer').merge(\n",
    "        international, on='code_year', how = 'outer').merge(\n",
    "        teqsa_avg, on=['TEQSA_type', 'ref_year'], how = 'outer')\n",
    "    # remove providers without a name\n",
    "    df = df[df.provider_name.notnull()]\n",
    "\n",
    "    # remove ref_year before 2012\n",
    "    df = df[df['ref_year'] > 2011]\n",
    "\n",
    "    df.ref_year = df.ref_year.astype(int)\n",
    "\n",
    "    # remove providers that no longer existed in the last year of the data collection (2017)\n",
    "    #still_exists = list(df[df['ref_year'] == 2017]['prv'])\n",
    "    #df = df[df.prv.isin(still_exists)]\n",
    "\n",
    "    # replace unlikely values with null\n",
    "    df['ssr_all'] = np.where((df.ssr_all < 0.00001), np.NaN ,df.ssr_all)\n",
    "    df['sessional_prop'] = np.where((df.sessional_prop < 0.00001), np.NaN ,df.sessional_prop)\n",
    "    df['sessional_prop'] = np.where((df.sessional_prop > 0.99999), np.NaN ,df.sessional_prop)\n",
    "\n",
    "\n",
    "    # remove redundant provider code\n",
    "    df = df.drop(['provider_code'], axis=1)\n",
    "    \n",
    "\n",
    "    return df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute(df):\n",
    "    '''a function to impute missing values using MICE'''\n",
    "    \n",
    "    # select numeric features\n",
    "    df2 = df[['primary_bfoe_prop',\n",
    "                'bfoe_entropy',\n",
    "                'bfoe_gini_impurity',\n",
    "                'postgrad_prop',\n",
    "                'int_prop',\n",
    "                'sessional_prop_type_avg',\n",
    "                'sessional_prop',\n",
    "                'senior_prop',\n",
    "                'ssr_all_type_avg',\n",
    "                'ssr_salaried_type_avg',\n",
    "                'ssr_all',\n",
    "                'success_dom',\n",
    "                'success_int',\n",
    "                'success_all',\n",
    "                'attrition_dom',\n",
    "                'attrition_int',\n",
    "                'attrition_all']]\n",
    "\n",
    "    # specify minimum and maximum values for imputation\n",
    "    min = [0.01, 0, 0, 0, 0, 0.01, 0.01, 0, 0, 0, 0.01, 1, 1, 1, 1, 1, 1]\n",
    "    max = [1, 3.05, 1, 1, 1, 1, 1, 1, 200, 200, 200, 100, 100, 100, 100, 100, 100]\n",
    "    \n",
    "    # instantiate imputer\n",
    "    mice_imputer = IterativeImputer(max_iter=10000, random_state=1, min_value=min, max_value=max)\n",
    "    \n",
    "    # fit imputation and return as a dataframe\n",
    "    df_imp = pd.DataFrame(mice_imputer.fit_transform(df2).round(decimals=6))\n",
    "    \n",
    "    # rename imputed columns\n",
    "    df_imp.columns = ['primary_bfoe_prop',\n",
    "                'bfoe_entropy',\n",
    "                'bfoe_gini_impurity',\n",
    "                'postgrad_prop',\n",
    "                'int_prop',\n",
    "                'sessional_prop_type_avg',\n",
    "                'sessional_prop',\n",
    "                'senior_prop',\n",
    "                'ssr_all_type_avg',\n",
    "                'ssr_salaried_type_avg',\n",
    "                'ssr_all',\n",
    "                'success_dom',\n",
    "                'success_int',\n",
    "                'success_all',\n",
    "                'attrition_dom',\n",
    "                'attrition_int',\n",
    "                'attrition_all']\n",
    "    \n",
    "    # specify columns to be overwritten with imputed data, noting that cells without NAs will be untouched\n",
    "    columns_to_overwrite = ['primary_bfoe_prop',\n",
    "                'bfoe_entropy',\n",
    "                'bfoe_gini_impurity',\n",
    "                'postgrad_prop',\n",
    "                'int_prop',\n",
    "                'sessional_prop_type_avg',\n",
    "                'sessional_prop',\n",
    "                'senior_prop',\n",
    "                'ssr_all_type_avg',\n",
    "                'ssr_salaried_type_avg',\n",
    "                'ssr_all',\n",
    "                'success_dom',\n",
    "                'success_int',\n",
    "                'success_all',\n",
    "                'attrition_dom',\n",
    "                'attrition_int',\n",
    "                'attrition_all']\n",
    "    \n",
    "    # drop columns to be overwritten from original dataset and replace with imputed data\n",
    "    df3 = df.drop(columns_to_overwrite, axis=1)\n",
    "    df3[columns_to_overwrite] = df_imp[columns_to_overwrite]\n",
    "\n",
    "    return df3[df3['ssr_all'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def staffAdjust(df_imp, sessional_multiplier = 1, ssr_multiplier = 1):\n",
    "    \n",
    "    df_imp = df_imp\n",
    "    \n",
    "    '''a function to adjust imputed staffing values based on sub-sector averages published by TEQSA'''\n",
    "\n",
    "    compare = df_imp[['ref_year','TEQSA_type',\n",
    "                    'sessional_prop_type_avg',\n",
    "                    'sessional_prop',\n",
    "                    'ssr_all_type_avg',\n",
    "                    'ssr_salaried_type_avg',\n",
    "                    'ssr_all']]\n",
    "\n",
    "    agg = compare.groupby(['ref_year','TEQSA_type']).mean().reset_index()\n",
    "    agg['sessional_diff'] = agg['sessional_prop_type_avg'] - agg['sessional_prop']\n",
    "    agg['ssr_all_diff'] = agg['ssr_all_type_avg'] - agg['ssr_all']\n",
    "    diff = agg.drop(['sessional_prop_type_avg', 'sessional_prop', 'ssr_all_type_avg', 'ssr_all', 'ssr_salaried_type_avg'], axis=1)\n",
    "\n",
    "    df_diff = df_imp.merge(diff, on=['ref_year', 'TEQSA_type'], how = 'left')\n",
    "\n",
    "    df_diff.loc[df_diff.TEQSA_type!='university', 'sessional_prop'] = sessional_multiplier * (df_diff.loc[df_diff.TEQSA_type!='university', 'sessional_prop'] + df_diff.loc[df_diff.TEQSA_type!='university', 'sessional_diff'])\n",
    "    df_diff.loc[df_diff.TEQSA_type!='university', 'ssr_all'] = ssr_multiplier * (df_diff.loc[df_diff.TEQSA_type!='university', 'ssr_all'] + df_diff.loc[df_diff.TEQSA_type!='university', 'ssr_all_diff'])\n",
    "\n",
    "    df_diff = df_diff.drop(['sessional_diff', 'ssr_all_diff', 'sessional_prop_type_avg', 'ssr_all_type_avg', 'ssr_salaried_type_avg'], axis=1)\n",
    "\n",
    "    df_diff['ssr_salaried'] = df_diff['ssr_all'] * (1 / (1 - df_diff['sessional_prop']))\n",
    "    \n",
    "    df = df_diff[['code_year',\n",
    "            'prv',\n",
    "            'provider_name',\n",
    "            'ref_year',\n",
    "            'type',\n",
    "            'TEQSA_type',\n",
    "            'ownership',\n",
    "            'profit',\n",
    "            'affiliation',\n",
    "            'affil_status',\n",
    "            'eftsl_sum',\n",
    "            'primary_bfoe',\n",
    "            'primary_bfoe_prop',\n",
    "            'bfoe_entropy',\n",
    "            'bfoe_gini_impurity',\n",
    "            'postgrad_prop',\n",
    "            'int_prop',\n",
    "            'sessional_prop',\n",
    "            'senior_prop',\n",
    "            'ssr_all',\n",
    "            'ssr_salaried',\n",
    "            'success_dom',\n",
    "            'success_int',\n",
    "            'success_all',\n",
    "            'attrition_dom',\n",
    "            'attrition_int',\n",
    "            'attrition_all']]\n",
    "\n",
    "    return df.round(decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    df_raw = joinData()\n",
    "    df_raw.to_csv('higher_ed_data_raw.csv', index = False)\n",
    "    \n",
    "    df_imp = impute(df_raw)\n",
    "    df_imp = staffAdjust(df_imp)\n",
    "    df_imp.to_csv('higher_ed_data_imputed.csv', index = False)\n",
    "    \n",
    "    df_dec = loadDecisions(max_year = 2021)\n",
    "    df_dec.to_csv('teqsa_decisions.csv', index = False)\n",
    "    \n",
    "    return df_imp, df_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     code_year       prv                               provider_name  \\\n",
       " 0    3006-2013  PRV12008      Australian Catholic University Limited   \n",
       " 1    3033-2013  PRV12002              Australian National University   \n",
       " 2    3003-2013  PRV12072                     Bond University Limited   \n",
       " 3    4374-2013  PRV12095                  Carnegie Mellon University   \n",
       " 4    2200-2013  PRV12073               Central Queensland University   \n",
       " ..         ...       ...                                         ...   \n",
       " 648  4468-2017  PRV14272                     South Metropolitan TAFE   \n",
       " 649  7073-2017  PRV12123                          Chisholm Institute   \n",
       " 650  7075-2017  PRV12049  Technical and Further Education Commission   \n",
       " 651  7338-2017  PRV14002                                     TAFE SA   \n",
       " 652  8071-2017  PRV14273                     North Metropolitan TAFE   \n",
       " \n",
       "      ref_year        type  TEQSA_type ownership          profit  affiliation  \\\n",
       " 0        2013  university  university    public  not_for_profit  non_aligned   \n",
       " 1        2013  university  university    public  not_for_profit          Go8   \n",
       " 2        2013  university  university   private  not_for_profit  non_aligned   \n",
       " 3        2013  university  university   private  not_for_profit  non_aligned   \n",
       " 4        2013  university  university    public  not_for_profit          RUN   \n",
       " ..        ...         ...         ...       ...             ...          ...   \n",
       " 648      2017        TAFE        TAFE    public  not_for_profit        NUHEP   \n",
       " 649      2017        TAFE        TAFE    public  not_for_profit        NUHEP   \n",
       " 650      2017        TAFE        TAFE    public  not_for_profit        NUHEP   \n",
       " 651      2017        TAFE        TAFE    public  not_for_profit        NUHEP   \n",
       " 652      2017        TAFE        TAFE    public  not_for_profit        NUHEP   \n",
       " \n",
       "     affil_status  ...  sessional_prop senior_prop  ssr_all  ssr_salaried  \\\n",
       " 0        current  ...           0.379       0.146   19.063        30.701   \n",
       " 1        current  ...           0.070       0.318    7.107         7.640   \n",
       " 2        current  ...           0.252       0.367   13.758        18.400   \n",
       " 3        current  ...           0.186       0.337    0.010         0.012   \n",
       " 4        current  ...           0.178       0.184   21.365        25.980   \n",
       " ..           ...  ...             ...         ...      ...           ...   \n",
       " 648      current  ...           0.371       0.216   10.028        15.931   \n",
       " 649      current  ...           0.320       0.133   19.306        28.405   \n",
       " 650      current  ...           0.276       0.175   14.927        20.625   \n",
       " 651      current  ...           0.233       0.126   13.498        17.591   \n",
       " 652      current  ...           0.216       0.288    9.515        12.135   \n",
       " \n",
       "      success_dom  success_int  success_all  attrition_dom  attrition_int  \\\n",
       " 0          89.20        88.16        89.10         14.140          13.36   \n",
       " 1          92.86        93.90        93.16         10.170           3.51   \n",
       " 2          76.90        88.60        80.18         11.000           9.04   \n",
       " 3          97.75        99.15        99.12          7.363           6.67   \n",
       " 4          83.37        82.93        83.24         26.480          16.59   \n",
       " ..           ...          ...          ...            ...            ...   \n",
       " 648        78.79        79.52        79.32         25.710          23.60   \n",
       " 649        85.13        67.90        75.10         21.950          35.29   \n",
       " 650        85.20        77.65        82.81         24.450          39.51   \n",
       " 651        73.21        73.54        73.30         48.480          16.67   \n",
       " 652        87.28        96.15        88.22         11.630           6.67   \n",
       " \n",
       "      attrition_all  \n",
       " 0            14.06  \n",
       " 1             8.72  \n",
       " 2            10.44  \n",
       " 3             6.67  \n",
       " 4            23.32  \n",
       " ..             ...  \n",
       " 648          24.19  \n",
       " 649          29.35  \n",
       " 650          28.81  \n",
       " 651          43.59  \n",
       " 652          10.89  \n",
       " \n",
       " [653 rows x 27 columns],\n",
       "            prv  ref_year      DecisionType dec_any_adverse dec_formal_adverse  \\\n",
       " 0     PRV12002      2013   Re-registration           False              False   \n",
       " 1     PRV12003      2015   Re-registration           False              False   \n",
       " 2     PRV12004      2013  Re-accreditation           False              False   \n",
       " 3     PRV12004      2013  Re-accreditation           False              False   \n",
       " 4     PRV12004      2015  Re-accreditation           False              False   \n",
       " ...        ...       ...               ...             ...                ...   \n",
       " 2486  PRV14334      2020     Accreditation           False              False   \n",
       " 2487  PRV14334      2020     Accreditation           False              False   \n",
       " 2488  PRV14334      2020     Accreditation           False              False   \n",
       " 2489  PRV14349      2020      Registration           False              False   \n",
       " 2490  PRV14349      2020     Accreditation           False              False   \n",
       " \n",
       "      dec_rejected dec_condition dec_staff_ratio dec_sessional dec_attrition  \\\n",
       " 0           False         False           False         False         False   \n",
       " 1           False         False           False         False         False   \n",
       " 2           False         False           False         False         False   \n",
       " 3           False         False           False         False         False   \n",
       " 4           False         False           False         False         False   \n",
       " ...           ...           ...             ...           ...           ...   \n",
       " 2486        False         False           False         False         False   \n",
       " 2487        False         False           False         False         False   \n",
       " 2488        False         False           False         False         False   \n",
       " 2489        False         False           False         False         False   \n",
       " 2490        False         False           False         False         False   \n",
       " \n",
       "      dec_progress  \n",
       " 0           False  \n",
       " 1           False  \n",
       " 2           False  \n",
       " 3           False  \n",
       " 4           False  \n",
       " ...           ...  \n",
       " 2486        False  \n",
       " 2487        False  \n",
       " 2488        False  \n",
       " 2489        False  \n",
       " 2490        False  \n",
       " \n",
       " [1997 rows x 11 columns])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
